#---------- Run PGA with error corrected reads generated by hifiasm ----------#

rule count_kmers_for_ec_reads:
    output:
        kff = "results_hs/hs-{k}/reads/{sample_id}.ec.kff"
    input:
        fasta="results_hs/hs-{k}/reads/{sample_id}.ec.fasta"
    threads: 32
    resources:
        mem_mb=125000,  # max_rss = 104393.51 MB (â‰ˆ 102 GB) + 20% buffer = 125000 MB
        runtime=2100,  # Runtime in seconds
        slurm_partition=choose_partition(40)
    shell:
        """
        # Count kmers from sequencing reads
        mkdir -p results_hs/hs-{wildcards.k}/reads/tmp_{wildcards.sample_id}.ec
        kmc -k29 -m128 -okff -t{threads} -fa {input.fasta} results_hs/hs-{wildcards.k}/reads/{wildcards.sample_id}.ec results_hs/hs-{wildcards.k}/reads/tmp_{wildcards.sample_id}.ec
        """

rule prepare_haplotype_sampling_for_ec_reads:
    output:
        sampled_ec_gbz="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.gbz",
        sampled_pg_vg_ec="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.pg.vg",
        snarls_ec="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.snarls",
        distance_index="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.dist",
        alignment_gaf="results_hs/alignment/hs-{k}/{sample_id}/alignments-combined.processed.ec.gaf",
        alignment_gaf_sorted="results_hs/alignment/hs-{k}/{sample_id}/alignments-combined.processed.ec.gaf.gz"
    input:
        kff="results_hs/hs-{k}/reads/{sample_id}.ec.kff",
        graph_gbz=config["graph_base"] + ".gbz",
        graph_hapl=config["graph_base"] + ".hapl",
        awk_script="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts/process_out.awk",
        ec_fq="results_hs/hs-{k}/{sample_id}/hifiasm/{sample_id}.ec.fq"
    params:
        k=config["HAPLOTYPE_SAMPLING"]["num_haps"],
        diploid_sampling="--diploid_sampling" if config["HAPLOTYPE_SAMPLING"]["diploid_sampling"] else ""
    benchmark: "benchmarks/{sample_id}/hs-{k}/prepare_haplotype_sampling_for_ec_reads.benchmark.txt"
    log: "logs/{sample_id}/hs-{k}/prepare_haplotype_sampling_for_ec_reads.log"
    threads: 32
    resources:
        mem_mb=160000,
        runtime=800*60,
        slurm_partition=choose_partition(800)
    shell:
        """
        echo "------Haplotype sampling of HG2 graph------"
        vg haplotypes -v 2 -t {threads} --include-reference {params.diploid_sampling} --num-haplotypes {params.k} \
            -i {input.graph_hapl} -k {input.kff} -g {output.sampled_ec_gbz} {input.graph_gbz}

        echo "------Convert the sampled HG2 graph to a PGVG graph------"
        vg convert -t {threads} {output.sampled_ec_gbz} -p > {output.sampled_pg_vg_ec}

        echo "------Compute snarls for the sampled HG2 graph------"
        vg snarls -t {threads} -T {output.sampled_ec_gbz} > {output.snarls_ec}

        echo "------Align reads to the sampled HG2 graph------"
        vg giraffe -t {threads} -b r10 -f {input.ec_fq} -Z {output.sampled_ec_gbz} --output-format gaf 2>> {log} | {input.awk_script} > {output.alignment_gaf}

        echo "------Sort and index the alignment file------"
        vg gamsort -t {threads} -p -G {output.alignment_gaf} | bgzip -c > {output.alignment_gaf_sorted}
        tabix -@ {threads} -p gaf {output.alignment_gaf_sorted}
        """


if config.get("RUN_GBZ_QUERY", False):
    ### Use GBZ base for DB construction and querying ###
    
    rule extract_top_level_chains_for_ec_reads:
        output:
            chains="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.chains"
        input:
            gbz="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.gbz",
            distance_index="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.dist"
        benchmark: "benchmarks/{sample_id}/hs-{k}/extract_top_level_chains_for_ec_reads.benchmark.txt"
        log: "logs/{sample_id}/hs-{k}/extract_top_level_chains_for_ec_reads.log"
        resources:
            mem_mb=13000,
            runtime=3*60,
            slurm_partition=choose_partition(3)
        shell:
            """
            vg chains -p -o {output.chains} {input.gbz} {input.distance_index} > {log} 2>&1
            """
    
    rule generate_gbz_db_for_ec_reads:
        output:
            gbz_db="results_hs/graph/{sample_id}/gbz_db/{sample_id}-{k}-sampled.ec.gbz.db"
        input:
            gbz="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.gbz",
            chains="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.chains"
        benchmark: "benchmarks/{sample_id}/hs-{k}/generate_gbz_db_for_ec_reads.benchmark.txt"
        log: "logs/{sample_id}/hs-{k}/generate_gbz_db_for_ec_reads.log"
        resources:
            mem_mb=7000,
            runtime=420,
            slurm_partition=choose_partition(7)
        shell:
            """
            gbz2db --chains {input.chains} --output {output.gbz_db} {input.gbz} 2> {log}
            """

    rule generate_gaf_db_for_ec_reads:
        output:
            gbwt="results_hs/alignment/hs-{k}/{sample_id}/gaf_db/alignments-combined.processed.ec.sorted.gbwt",
            gaf="results_hs/alignment/hs-{k}/{sample_id}/gaf_db/alignments-combined.processed.ec.sorted.gaf.gz",
            gaf_db="results_hs/alignment/hs-{k}/{sample_id}/gaf_db/alignments-combined.processed.ec.sorted.gaf.db"
        input:
            combined_gaf="results_hs/alignment/hs-{k}/{sample_id}/alignments-combined.processed.ec.gaf"
        benchmark: "benchmarks/{sample_id}/hs-{k}/generate_gaf_db_for_ec_reads.benchmark.txt"
        log: "logs/{sample_id}/hs-{k}/generate_gaf_db_for_ec_reads.log"
        threads: 2
        resources:
            mem_mb=210000,
            runtime=15000,
            slurm_partition=choose_partition(250)
        shell:
            """
            set -e -o pipefail
            echo "Sorting GAF and creating GBWT index..."
            vg gamsort --progress --threads {threads} --gbwt-output {output.gbwt} --gaf-input {input.combined_gaf} | bgzip --threads 16 > {output.gaf}
            
            echo "Creating GAF database..."
            gaf2db -o {output.gaf_db} -g {output.gbwt} --block-size 10 {output.gaf}
            """
        
    ### QUERY USING GBZ DB
    rule query_gbz_gaf_db_for_ec_reads:
        output:
            subgraph_gaf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.gaf",
            subgraph_gfa="results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.gfa",
            subgraph_pg_vg="results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.pg.vg",
            subgraph_pg_dist="results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.pg.dist"
        input:
            gbz_db="results_hs/graph/{sample_id}/gbz_db/{sample_id}-{k}-sampled.ec.gbz.db",
            gaf_db="results_hs/alignment/hs-{k}/{sample_id}/gaf_db/alignments-combined.processed.ec.sorted.gaf.db"
        params:
            contig=config['region']['chromosome'],
            interval=config['region']['start'] + ".." + config['region']['end'],
        benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/query_gbz_gaf_db_for_ec_reads.benchmark.txt"
        log: "logs/{sample_id}/hs-{k}/{region_id}/query_gbz_gaf_db_for_ec_reads.log"
        threads: 16
        resources:
            mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=500),
            runtime=20*60,
            slurm_partition=choose_partition(20)
        run:
            import subprocess
            # query the given interval to get the reads and subgraph
            query_cmd = (
                f"query --sample CHM13 --contig {params.contig} --context 0 --snarls --interval {params.interval} "
                f"--gaf-base {input.gaf_db} --gaf-output {output.subgraph_gaf} {input.gbz_db} > {output.subgraph_gfa} 2>> {log}"
            )
            subprocess.run(query_cmd, shell=True, check=True)
            subprocess.run(f"vg convert -g {output.subgraph_gfa} -p > {output.subgraph_pg_vg}", shell=True, check=True)        
            subprocess.run(f"vg index {output.subgraph_pg_vg} --threads {threads} --dist-name {output.subgraph_pg_dist}", shell=True, check=True)

    if not config.get("USE_FULL_GRAPH"):

        rule generate_anchors_dictionary_with_subgraph_for_ec_reads:
            output:
                anchors_dictionary="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.pkl"
            input:
                vg_anchors_config=config["VG_ANCHORS"]["conf"],
                subgraph_pg_dist="results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.pg.dist",
                subgraph_pg_vg="results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.pg.vg"
            benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/generate_anchors_dictionary_with_subgraph_for_ec_reads.benchmark.txt"
            log: "logs/{sample_id}/hs-{k}/{region_id}/generate_anchors_dictionary_with_subgraph_for_ec_reads.log"
            resources:
                mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=1000),
                runtime=10*60,
                slurm_partition=choose_partition(10)
            shell:
                """
                vg-anchors --config {input.vg_anchors_config} build --graph {input.subgraph_pg_vg} --index {input.subgraph_pg_dist} \
                    --output-prefix results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph > {log} 2>&1
                """

        rule get_anchors_from_gaf_with_subgraph_for_ec_reads:
            output:
                anchors="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.extended.jsonl",
                params_log="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/params_run.log",
                **({} if not config.get("RUN_DEBUGGING") else {"read_processed_tsv": "results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.reads_processed.tsv"})
            input:
                vg_anchors_config=config["VG_ANCHORS"]["conf"],
                anchors_dictionary="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.pkl",
                chunked_gaf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.gaf",
                subgraph_pg_vg="results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.pg.vg",
                chunked_fasta="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/{sample_id}.subregion.fasta"
            benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/get_anchors_from_gaf_with_subgraph_for_ec_reads.benchmark.txt"
            log: "logs/{sample_id}/hs-{k}/{region_id}/get_anchors_from_gaf_with_subgraph_for_ec_reads.log"
            params:
                processes=32
            resources:
                mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=1000),
                runtime=30*60,
                slurm_partition=choose_partition(30)
            shell:
                """
                vg-anchors --config {input.vg_anchors_config} get-anchors \
                    --dictionary {input.anchors_dictionary} \
                    --threads {params.processes} \
                    --graph {input.subgraph_pg_vg} \
                    --alignment {input.chunked_gaf} \
                    --fasta {input.chunked_fasta} \
                    --output results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.anchors.json > {log} 2>&1
                """
    
    else:
        rule generate_anchors_dictionary_with_full_graph_and_gbz_query_for_ec_reads:
            output:
                anchors_dictionary="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.pkl"
            input:
                vg_anchors_config=config["VG_ANCHORS"]["conf"],
                subgraph_pg_dist="results_hs/{k}/{sample_id}/{region_id}/ec/query/subgraph.pg.dist",
                sampled_pg_vg="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.pg.vg",
            benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/generate_anchors_dictionary_with_full_graph_and_gbz_query_for_ec_reads.benchmark.txt"
            log: "logs/{sample_id}/hs-{k}/{region_id}/generate_anchors_dictionary_with_full_graph_and_gbz_query_for_ec_reads.log"
            resources:
                mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=1000),
                runtime=100*60,
                slurm_partition=choose_partition(100)
            shell:
                """
                echo "Generating anchors dictionary with full graph and GBZ query..."
                vg-anchors --config {input.vg_anchors_config} build --graph {input.sampled_pg_vg} --index {input.subgraph_pg_dist} \
                    --output-prefix results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph > {log} 2>&1
                """

        rule get_anchors_from_gaf_with_full_graph_and_gbz_query_for_ec_reads:
            output:
                anchors="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.extended.jsonl",
                params_log="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/params_run.log",
                **({} if not config.get("RUN_DEBUGGING") else {"read_processed_tsv": "results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.reads_processed.tsv"})
            input:
                vg_anchors_config=config["VG_ANCHORS"]["conf"],
                anchors_dictionary="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.pkl",
                chunked_gaf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.gaf",
                sampled_pg_vg="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.pg.vg",
                chunked_fasta="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/{sample_id}.subregion.fasta"
            params:
                processes=32
            benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/get_anchors_from_gaf_with_full_graph_and_gbz_query_for_ec_reads.benchmark.txt"
            log: "logs/{sample_id}/hs-{k}/{region_id}/get_anchors_from_gaf_with_full_graph_and_gbz_query_for_ec_reads.log"
            resources:
                mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=1000),
                runtime=100*60,
                slurm_partition=choose_partition(100)
            shell:
                """
                echo "Getting anchors from GAF with full graph and GBZ query..."
                vg-anchors --config {input.vg_anchors_config} get-anchors \
                    --dictionary {input.anchors_dictionary} \
                    --threads {params.processes} \
                    --graph {input.sampled_pg_vg} \
                    --alignment {input.chunked_gaf} \
                    --fasta {input.chunked_fasta} \
                    --output results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.anchors.json > {log} 2>&1
                """

else:
    rule vg_chunk_and_index_for_ec_reads:
        output:
            subgraph_vg_ec="results_hs/hs-{k}/{sample_id}/{region_id}/ec/chunk/subgraph.vg",
            chunked_gaf_ec="results_hs/hs-{k}/{sample_id}/{region_id}/ec/chunk/subgraph.gaf",
            subgraph_pg_vg_ec="results_hs/hs-{k}/{sample_id}/{region_id}/ec/chunk/subgraph.pg.vg",
            subgraph_pg_gfa_ec="results_hs/hs-{k}/{sample_id}/{region_id}/ec/chunk/subgraph.pg.gfa",
            subgraph_pg_dist_ec="results_hs/hs-{k}/{sample_id}/{region_id}/ec/chunk/subgraph.pg.dist"
        input:
            sorted_gaf_ec="results_hs/alignment/hs-{k}/{sample_id}/alignments-combined.processed.ec.gaf.gz",
            sampled_gbz_ec="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.gbz",
            snarls_ec="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.snarls"
        params:
            region="CHM13#0#" + config['region']['chromosome'] + ":" + config['region']['start'] + "-" + config['region']['end'],
            region_underscore="_0_CHM13#0#" + config['region']['chromosome'] + "_" + config['region']['start'] + "_" + config['region']['end'],
            prefix="results_hs/hs-{k}/{sample_id}/{region_id}/ec/chunk/subgraph",
            region_id=config["region_id"]
        benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/vg_chunk_and_index_for_ec_reads.benchmark.txt"
        log: "logs/{sample_id}/hs-{k}/{region_id}/vg_chunk_and_index_for_ec_reads.log"
        threads: 8
        resources:
            mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=1000),
            runtime=100*60,
            slurm_partition=choose_partition(100)
        shell:
            """
            mkdir -p results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/chunk
            vg chunk -a {input.sorted_gaf_ec} -F -g -x {input.sampled_gbz_ec} -p {params.region} -S {input.snarls_ec} --trace -t {threads} -b {params.prefix} > {output.subgraph_vg_ec} 2> {log}
            mv {params.prefix}{params.region_underscore}.gaf {output.chunked_gaf_ec}
            vg convert -p {output.subgraph_vg_ec} > {output.subgraph_pg_vg_ec}
            vg convert -f {output.subgraph_pg_vg_ec} > {output.subgraph_pg_gfa_ec}
            vg index -t {threads} {output.subgraph_pg_vg_ec} --dist-name {output.subgraph_pg_dist_ec}
            """

    rule generate_anchors_dictionary_for_ec_reads:
        output:
            anchors_dictionary="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.pkl",
        input:
            vg_anchors_config=config["VG_ANCHORS"]["conf"],
            subgraph_pg_dist="results_hs/hs-{k}/{sample_id}/{region_id}/ec/chunk/subgraph.pg.dist",
            sampled_pg_vg="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.pg.vg"
        benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/generate_anchors_dictionary_for_ec_reads.benchmark.txt"
        log: "logs/{sample_id}/hs-{k}/{region_id}/generate_anchors_dictionary_for_ec_reads.log"
        resources:
            mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=1000),
            runtime=100*60,
            slurm_partition=choose_partition(100)
        shell:
            """
            vg-anchors --config {input.vg_anchors_config} build --graph {input.sampled_pg_vg} --index {input.subgraph_pg_dist} \
                --output-prefix results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph > {log} 2>&1
            """

    rule get_anchors_from_gaf_for_ec_reads:
        output:
            anchors="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.extended.jsonl",
            params_log="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/params_run.log",
            **({} if not config.get("RUN_DEBUGGING") else {"read_processed_tsv": "results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.reads_processed.tsv"})
        input:
            vg_anchors_config=config["VG_ANCHORS"]["conf"],
            anchors_dictionary="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.pkl",
            chunked_gaf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/chunk/subgraph.gaf",
            sampled_pg_vg="results_hs/graph/{sample_id}/{sample_id}-{k}-sampled.ec.pg.vg",
            chunked_fasta="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/{sample_id}.subregion.fasta"
        benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/get_anchors_from_gaf_for_ec_reads.benchmark.txt"
        log: "logs/{sample_id}/hs-{k}/{region_id}/get_anchors_from_gaf_for_ec_reads.log"
        params:
            processes=64
        resources:
            mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=1000),
            runtime=100*60,
            slurm_partition=choose_partition(100)
        shell:
            """
            vg-anchors --config {input.vg_anchors_config} get-anchors \
                --dictionary {input.anchors_dictionary} \
                --threads {params.processes} \
                --graph {input.sampled_pg_vg} \
                --alignment {input.chunked_gaf} \
                --fasta {input.chunked_fasta} \
                --output results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.anchors.json > {log} 2>&1
            """


rule chunk_fasta_for_ec_reads:
    output:
        chunked_fasta = "results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/{sample_id}.subregion.fasta"
    input:
        fasta="results_hs/hs-{k}/reads/{sample_id}.ec.fasta",
        chunked_gaf=(
            "results_hs/hs-{k}/{sample_id}/{region_id}/ec/query/subgraph.gaf"
            if config.get("RUN_GBZ_QUERY", False)
            else "results_hs/hs-{k}/{sample_id}/{region_id}/ec/chunk/subgraph.gaf"
        )
    benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/chunk_fasta_for_ec_reads.benchmark.txt"
    log: "logs/{sample_id}/hs-{k}/{region_id}/chunk_fasta_for_ec_reads.log"
    container:
        "docker://pegi3s/seqkit:latest"
    shell:
        """
        # Extract READ IDs from chunked GAF and then extract fasta records for these reads
        cut -f1 {input.chunked_gaf} | sort -u -T {config[TMPDIR]}| seqkit grep -f - {input.fasta} > {output.chunked_fasta}
        """


rule run_shasta_assembly_for_ec_reads:
	output: "results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/ShastaRun/Assembly.fasta"
	input:
		shasta=config["SHASTA"]["bin"],
		shasta_conf=config["SHASTA"]["conf"],
		chunked_fasta="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/{sample_id}.subregion.fasta",
		anchors="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.extended.jsonl"
	benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/run_shasta_assembly_for_ec_reads.benchmark.txt"
	log: "logs/{sample_id}/hs-{k}/{region_id}/run_shasta_assembly_for_ec_reads.log"
	resources:
		mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.5, min_mb=10000),
		runtime=60*60,
		slurm_partition=choose_partition(60)
	shell:
		"""
		## make a copy of the anchors.json for Shasta
		cp {input.anchors} results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/shasta/anchors.json
		rm -rf results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/shasta/ShastaRun
		
		{input.shasta} --input {input.chunked_fasta} --assemblyDirectory results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/shasta/ShastaRun \
			--config {input.shasta_conf} --anchors results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/shasta/anchors.json --memoryMode filesystem --memoryBacking disk > {log} 2>&1
		"""

rule get_extended_anchor_stats_for_ec_reads:
    output:
        anchor_reads_info="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/extended_anchor_reads_info.tsv",
        anchor_stats_dir=directory("results_hs/hs-{k}/{sample_id}/{region_id}/ec/extended_anchor_stats")
    input:
        scripts_dir="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts",
        anchors="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.extended.jsonl",
        subregion_shasta_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/ShastaRun/Assembly.fasta",
        chunked_fasta="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/{sample_id}.subregion.fasta"
    params:
        region=config['region']['chromosome'] + ":" + config['region']['start'] + "-" + config['region']['end'],
    benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/get_extended_anchor_stats_for_ec_reads.benchmark.txt"
    log: "logs/{sample_id}/hs-{k}/{region_id}/get_extended_anchor_stats_for_ec_reads.log"
    resources:
        mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=400),
        runtime=10*60,
        slurm_partition=choose_partition(10)
    shell:
        """
        mkdir -p results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/extended_anchor_stats
        # Since this JSON is confusing to interpret, convert it to a TSV...
        python3 {input.scripts_dir}/preprocess_vganchor_outfiles_extention.py -j {input.anchors}
        # Next, generate anchor stats plots...
        Rscript {input.scripts_dir}/get_extended_anchor_stats.R -d results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec -o ont_r10_{wildcards.region_id} -r {params.region} > {log} 2>&1
        """

# #------- Generate anchor sequence TSV --------# (Can plug into rule above if needed)
# master_table_tsv=results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/extended_anchor_stats/ont_r10_{wildcards.region_id}_anchors_master_table.tsv
# python {input.scripts_dir}/process_anchor_seqs.py -j {input.anchors} -m $master_table_tsv -f {input.chunked_fasta} -o results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/extended_anchor_stats/ont_r10_{wildcards.region_id}        

if config.get("RUN_DEBUGGING"):

    rule get_reliable_snarl_stats_for_ec_reads:
        output:
            reliable_snarl_stats_dir=directory("results_hs/hs-{k}/{sample_id}/{region_id}/ec/reliable_snarl_stats"),
            snarl_compatibility_fractions="results_hs/hs-{k}/{sample_id}/{region_id}/ec/reliable_snarl_stats/snarl_compatibility_fractions.tsv"
        input:
            anchors="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.extended.jsonl",
            scripts_dir="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts",
        benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/get_reliable_snarl_stats_for_ec_reads.benchmark.txt"
        log: "logs/{sample_id}/hs-{k}/{region_id}/get_reliable_snarl_stats_for_ec_reads.log"
        resources:
            mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
            runtime=10*60,
            slurm_partition=choose_partition(10)
        shell:
            """
            #------- Generate reliable snarl stats --------#
            output_dir=results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/reliable_snarl_stats
            reliable_snarls_tsv=results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.anchors.json.reliable_snarls.tsv
            snarl_compatibility_json=results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.anchors.json.snarl_compatibility.jsonl
            snarl_coverage_json=results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.anchors.json.snarl_coverage.jsonl
            snarl_allelic_coverage_json=results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.anchors.json.snarl_allelic_coverage.jsonl
            snarl_allelic_coverage_extended_json=results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.anchors.json.snarl_allelic_coverage_extended.jsonl
            snarl_variant_type_json=results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.anchors.json.snarl_variant_type.jsonl
            snarl_positions_tsv=results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.sizes.tsv

            Rscript {input.scripts_dir}/reliable_snarl_stats_test.R $reliable_snarls_tsv $snarl_compatibility_json $snarl_coverage_json $snarl_allelic_coverage_json $snarl_allelic_coverage_extended_json $snarl_variant_type_json $snarl_positions_tsv $output_dir >> {log} 2>&1
            """
    
    rule get_debugging_files_for_ec_reads:
        output:
            nodes_info_tsv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/debugging/{region_id}_nodes_info.tsv",
            read_traversals_zip="results_hs/hs-{k}/{sample_id}/{region_id}/ec/debugging/{region_id}_read_traversals.zip",
            snarls_bandage_csv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/debugging/{region_id}_snarls.bandage.csv"
        input:
            script_dir="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts",
            read_processed_tsv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/subgraph.anchors.json.reads_processed.tsv",
            snarl_compatibility="results_hs/hs-{k}/{sample_id}/{region_id}/ec/reliable_snarl_stats/snarl_compatibility_fractions.tsv"
        benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/get_debugging_files_for_ec_reads.benchmark.txt"
        resources:
            mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=500),
            runtime=15*60,
            slurm_partition=choose_partition(15)
        shell:
            """
            python {input.script_dir}/process_read_processed_for_bandage.py {input.read_processed_tsv} -o {output.nodes_info_tsv}
            # selected columns for bandage and convert to CSV
            cut -f1,2,5,7 {output.nodes_info_tsv} | tr '\\t' ',' > results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/debugging/{wildcards.region_id}_nodes_info.bandage.csv
            
            # read alignments for bandage
            python {input.script_dir}/extract_read_alignments_for_bandage.py {input.read_processed_tsv} {output.nodes_info_tsv} -o {output.read_traversals_zip}

            # reliable/unreliable snarls for bandage
            snarl_dict="results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/anchors/subgraph.forward_dict.csv"
            python {input.script_dir}/map_snarls_bandage.py $snarl_dict {input.snarl_compatibility} {output.nodes_info_tsv} -o {output.snarls_bandage_csv}
            """

rule align_assembly_to_chunked_reference_for_ec_reads:
	output:
		paf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/assembly_alignment/{sample_id}_{region_id}_ZOOMED_shasta_to_hg002_minimap_{asm_preset}.paf",
		csv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/assembly_alignment/{sample_id}_{region_id}_ZOOMED_shasta_to_hg002_minimap_{asm_preset}.csv"
	input:
		analyzePaf_bin=config["ANALYSEPAF"]["bin"],
		hg002_reference_chunked="results_hs/hs-{k}/{sample_id}/{region_id}/assembly_alignment/hg002.chunked.fasta",
		subregion_shasta_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/ShastaRun/Assembly.fasta"
	params:
		asm_preset=config["MINIMAP"]["asmPreset"]
	benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/align_assembly_to_chunked_reference_for_ec_reads_{asm_preset}.benchmark.txt"
	log: "logs/{sample_id}/hs-{k}/{region_id}/align_assembly_to_chunked_reference_for_ec_reads_{asm_preset}.log"
	container: "docker://mkolmogo/card_minimap2:2.23"
	threads: 8
	resources:
		mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=400),
		runtime=10*60,
		slurm_partition=choose_partition(10)
	shell:
		"""
		minimap2 -t {threads} -I 20G -cx {params.asm_preset} -K 1M --eqx --cs {input.hg002_reference_chunked} {input.subregion_shasta_assembly} > {output.paf}
		{input.analyzePaf_bin} \
			--input {output.paf} \
			--output results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/assembly_alignment/{wildcards.sample_id}_{wildcards.region_id}_ZOOMED_shasta_to_hg002_minimap_{wildcards.asm_preset} \
			--pixelsPerMb 600 --minAlignmentQuality 1 --minAlignmentLength 0 > {log} 2>&1
		"""

rule run_displayPafAlignments_for_ec_reads:
	output:
		csv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/assembly_alignment/{sample_id}_{region_id}_ZOOMED_shasta_to_hg002_minimap_{asm_preset}_displayPaf.csv"
	input:
		displayPaf_bin=config["DISPLAYPAF"]["bin"],
		hg002_reference_chunked="results_hs/hs-{k}/{sample_id}/{region_id}/assembly_alignment/hg002.chunked.fasta",
		subregion_shasta_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/ShastaRun/Assembly.fasta",
		paf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/assembly_alignment/{sample_id}_{region_id}_ZOOMED_shasta_to_hg002_minimap_{asm_preset}.paf",
	params:
		asm_preset=config["MINIMAP"]["asmPreset"],
	benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/run_displayPafAlignments_for_ec_reads_{asm_preset}.benchmark.txt"
	log: "logs/{sample_id}/hs-{k}/{region_id}/run_displayPafAlignments_for_ec_reads_{asm_preset}.log"
	resources:
		mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
		runtime=10*60,
		slurm_partition=choose_partition(10)
	shell:
		"""
		{input.displayPaf_bin} \
			--paf {input.paf} -r {input.hg002_reference_chunked} -a {input.subregion_shasta_assembly} \
			--output results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/assembly_alignment/{wildcards.sample_id}_{wildcards.region_id}_ZOOMED_shasta_to_hg002_minimap_{wildcards.asm_preset}_displayPaf \
			--minAlignmentQuality 1 --minAlignmentLength 0 > {log} 2>&1	
		"""

#-------Using shasta alignment coordinates to hg002, chunk hg002 reference for hifiasm-------#
rule chunk_hg002_reference_for_hifiasm_using_shasta_alignment_coordinates_for_ec_reads:
    output:
        hg002_reference_chunked_for_hifiasm="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/hg002.chunked.{asm_preset}.for_hifiasm.fasta",
        coords_tsv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/hg002.chunked.{asm_preset}.for_hifiasm.coords.tsv"
    input:
        hg002_reference=config["HG002v101_ref"],
        script="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts/chunk_hg002_reference_for_hifiasm_using_shasta_alignments.py",
        shasta_csv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/assembly_alignment/{sample_id}_{region_id}_ZOOMED_shasta_to_hg002_minimap_{asm_preset}.csv",
    params:
        asm_preset=config["MINIMAP"]["asmPreset"]
    benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/chunk_hg002_reference_for_hifiasm_using_shasta_alignment_coordinates_for_ec_reads_{asm_preset}.benchmark.txt"
    log: "logs/{sample_id}/hs-{k}/{region_id}/chunk_hg002_reference_for_hifiasm_using_shasta_alignment_coordinates_for_ec_reads_{asm_preset}.log"
    resources:
        mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
        runtime=10*60,
        slurm_partition=choose_partition(10)
    shell:
        """
        python3 {input.script} {input.shasta_csv} {input.hg002_reference} \
            results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/hifiasm_assembly \
            hg002.chunked.{wildcards.asm_preset} > {log} 2>&1
        """


rule extract_hifiasm_subregion_assembly_for_ec_reads:
    output:
        hifiasm_subregion_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}.{asm_preset}.hifiasm.subregion.fasta"
    input:
        script="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts/extract_subregion_contigs.py",
        bam="results_hs/hs-{k}/{sample_id}/hifiasm_alignment/{sample_id}_hifiasm_to_hg002_minimap_{asm_preset}.bam",
        hifiasm_fasta="results_hs/hs-{k}/{sample_id}/hifiasm_alignment/{sample_id}.hifiasm.fasta",
        coords_tsv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/hg002.chunked.{asm_preset}.for_hifiasm.coords.tsv"
    params:
        asm_preset=config["MINIMAP"]["asmPreset"]
    benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/extract_hifiasm_subregion_assembly_for_ec_reads_{asm_preset}.benchmark.txt"
    log: "logs/{sample_id}/hs-{k}/{region_id}/extract_hifiasm_subregion_assembly_for_ec_reads_{asm_preset}.log"
    resources:
        mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
        runtime=10*60,
        slurm_partition=choose_partition(10)
    shell:
        """
        python3 {input.script} {input.bam} {input.coords_tsv} {input.hifiasm_fasta} {output.hifiasm_subregion_assembly} > {log} 2>&1
        """

rule align_hifiasm_subregion_assembly_to_chunked_hg002_reference_for_ec_reads:
    output:
        paf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}_{region_id}_hifiasm_subregion_to_hg002_minimap_{asm_preset}.paf",
        csv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}_{region_id}_hifiasm_subregion_to_hg002_minimap_{asm_preset}.csv"
    input:
        analyzePaf_bin=config["ANALYSEPAF"]["bin"],
        hg002_reference_chunked_for_hifiasm="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/hg002.chunked.{asm_preset}.for_hifiasm.fasta",
        hifiasm_subregion_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}.{asm_preset}.hifiasm.subregion.fasta"
    params:
        asm_preset=config["MINIMAP"]["asmPreset"]
    benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/align_hifiasm_subregion_assembly_to_chunked_hg002_reference_for_ec_reads_{asm_preset}.benchmark.txt"
    log: "logs/{sample_id}/hs-{k}/{region_id}/align_hifiasm_subregion_assembly_to_chunked_hg002_reference_for_ec_reads_{asm_preset}.log"
    threads: 16
    resources:
        mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
        runtime=60*60,
        slurm_partition=choose_partition(60)
    shell:
        """
        minimap2 -t {threads} -I 20G -cx {params.asm_preset} -K 1M --eqx --cs {input.hg002_reference_chunked_for_hifiasm} {input.hifiasm_subregion_assembly} > {output.paf}
        {input.analyzePaf_bin} \
            --input {output.paf} \
            --output results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/hifiasm_assembly/{wildcards.sample_id}_{wildcards.region_id}_hifiasm_subregion_to_hg002_minimap_{wildcards.asm_preset} \
            --pixelsPerMb 1000 --minAlignmentQuality 0 > {log} 2>&1
        """


#------ Align r_utg hifiasm assembly to chunked hg002 reference for hifiasm assembly -------#
rule extract_r_utg_hifiasm_subregion_assembly_for_ec_reads:
    output:
        r_utg_hifiasm_subregion_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}.{asm_preset}.hifiasm.r_utg.subregion.fasta"
    input:
        script="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts/extract_subregion_contigs.py",
        bam="results_hs/hs-{k}/{sample_id}/hifiasm_alignment/{sample_id}_r_utg_to_hg002_minimap_{asm_preset}.bam",
        bai="results_hs/hs-{k}/{sample_id}/hifiasm_alignment/{sample_id}_r_utg_to_hg002_minimap_{asm_preset}.bam.bai",
        coords_tsv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/hg002.chunked.{asm_preset}.for_hifiasm.coords.tsv",
        hifiasm_r_utg_fasta="results_hs/hs-{k}/{sample_id}/hifiasm/{sample_id}.bp.r_utg.fasta"
    params:
        asm_preset=config["MINIMAP"]["asmPreset"]
    benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/extract_r_utg_hifiasm_subregion_assembly_for_ec_reads_{asm_preset}.benchmark.txt"
    log: "logs/{sample_id}/hs-{k}/{region_id}/extract_r_utg_hifiasm_subregion_assembly_for_ec_reads_{asm_preset}.log"
    resources:
        mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
        runtime=10*60,
        slurm_partition=choose_partition(10)
    shell:
        """
        python3 {input.script} {input.bam} {input.coords_tsv} {input.hifiasm_r_utg_fasta} {output.r_utg_hifiasm_subregion_assembly} > {log} 2>&1
        """

rule align_r_utg_hifiasm_subregion_assembly_to_chunked_hg002_reference_for_ec_reads:
    output:
        paf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}_{region_id}_r_utg_hifiasm_subregion_to_hg002_minimap_{asm_preset}.paf",
        csv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}_{region_id}_r_utg_hifiasm_subregion_to_hg002_minimap_{asm_preset}.csv"
    input:
        analyzePaf_bin=config["ANALYSEPAF"]["bin"],
        hg002_reference_chunked_for_hifiasm="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/hg002.chunked.{asm_preset}.for_hifiasm.fasta",
        r_utg_hifiasm_subregion_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}.{asm_preset}.hifiasm.r_utg.subregion.fasta"
    params:
        asm_preset=config["MINIMAP"]["asmPreset"]
    benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/align_r_utg_hifiasm_subregion_assembly_to_chunked_hg002_reference_for_ec_reads_{asm_preset}.benchmark.txt"
    log: "logs/{sample_id}/hs-{k}/{region_id}/align_r_utg_hifiasm_subregion_assembly_to_chunked_hg002_reference_for_ec_reads_{asm_preset}.log"
    threads: 16
    resources:
        mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
        runtime=60*60,
        slurm_partition=choose_partition(60)
    shell:
        """
        minimap2 -t {threads} -I 20G -cx {params.asm_preset} -K 1M --eqx --cs {input.hg002_reference_chunked_for_hifiasm} {input.r_utg_hifiasm_subregion_assembly} > {output.paf}
        {input.analyzePaf_bin} \
            --input {output.paf} \
            --output results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/hifiasm_assembly/{wildcards.sample_id}_{wildcards.region_id}_r_utg_hifiasm_subregion_to_hg002_minimap_{wildcards.asm_preset} \
            --pixelsPerMb 1000 --minAlignmentQuality 1 > {log} 2>&1
        """

rule run_displayPafAlignments_for_r_utg_hifiasm_subregion_assembly:
	output:
		filtered_paf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}_{region_id}_r_utg_hifiasm_subregion_to_hg002_minimap_{asm_preset}.filtered.paf",
		csv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_alignment/{sample_id}_{region_id}_r_utg_hifiasm_subregion_to_hg002_minimap_{asm_preset}_displayPaf.csv",
	input:
		displayPaf_bin=config["DISPLAYPAF"]["bin"],
		hg002_reference_chunked_for_hifiasm="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/hg002.chunked.{asm_preset}.for_hifiasm.fasta",
		r_utg_hifiasm_subregion_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}.{asm_preset}.hifiasm.r_utg.subregion.fasta",
		paf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}_{region_id}_r_utg_hifiasm_subregion_to_hg002_minimap_{asm_preset}.paf",
		csv="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}_{region_id}_r_utg_hifiasm_subregion_to_hg002_minimap_{asm_preset}.csv",
		py_script="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts/filter_paf_to_csv_alignments.py"
	params:
		asm_preset=config["MINIMAP"]["asmPreset"],
	benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/run_displayPafAlignments_for_r_utg_hifiasm_subregion_assembly_{asm_preset}.benchmark.txt"
	log: "logs/{sample_id}/hs-{k}/{region_id}/run_displayPafAlignments_for_r_utg_hifiasm_subregion_assembly_{asm_preset}.log"
	resources:
		mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
		runtime=10*60,
		slurm_partition=choose_partition(10)
	shell:
		"""
		# FILTER paf to only include alignments in the CSV
		python {input.py_script} --csv {input.csv} --paf {input.paf} --output {output.filtered_paf}
		
		{input.displayPaf_bin} \
			--paf {output.filtered_paf} -r {input.hg002_reference_chunked_for_hifiasm} -a {input.r_utg_hifiasm_subregion_assembly} \
			--output results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/hifiasm_alignment/{wildcards.sample_id}_{wildcards.region_id}_r_utg_hifiasm_subregion_to_hg002_minimap_{wildcards.asm_preset}_displayPaf \
			--minAlignmentQuality 1 --minAlignmentLength 0 > {log} 2>&1		
		"""

#------ Align shasta assembly to hifiasm assembly --------#
rule shasta_to_hifiasm_alignment_for_ec_reads:
	output:
		shasta_to_hifiasm_alignment_paf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta_to_hifiasm_alignment/{sample_id}_{region_id}_shasta_to_hifiasm_minimap_{asm_preset}.paf",
		shasta_to_hifiasm_alignment_bam="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta_to_hifiasm_alignment/{sample_id}_{region_id}_shasta_to_hifiasm_minimap_{asm_preset}.bam",
		shasta_to_hifiasm_alignment_bai="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta_to_hifiasm_alignment/{sample_id}_{region_id}_shasta_to_hifiasm_minimap_{asm_preset}.bam.bai",
	input:
		analyzePaf_bin=config["ANALYSEPAF"]["bin"],
		# the subregion assembly from the final hifiasm assembly
		# hifiasm_subregion_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}.{asm_preset}.hifiasm.subregion.fasta",
		# the subregion assembly from the r_utg hifiasm assembly
		hifiasm_subregion_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/hifiasm_assembly/{sample_id}.{asm_preset}.hifiasm.r_utg.subregion.fasta",
		shasta_assembly="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta/ShastaRun/Assembly.fasta",
	params:
		asm_preset=config["MINIMAP"]["asmPreset"]
	benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/shasta_to_hifiasm_alignment_for_ec_reads_{asm_preset}.benchmark.txt"
	log: "logs/{sample_id}/hs-{k}/{region_id}/shasta_to_hifiasm_alignment_for_ec_reads_{asm_preset}.log"
	threads: 16
	resources:
		mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
		runtime=60*60,
		slurm_partition=choose_partition(60)
	shell:
		"""
		# Generate index for hifiasm assembly
		samtools faidx {input.hifiasm_subregion_assembly}

		minimap2 -t {threads} -I 20G -cx {params.asm_preset} -K 1M --eqx --cs {input.hifiasm_subregion_assembly} {input.shasta_assembly} > {output.shasta_to_hifiasm_alignment_paf}

		minimap2 -t {threads} -I 20G -ax {params.asm_preset} -K 1M --eqx --cs {input.hifiasm_subregion_assembly} {input.shasta_assembly} | \
			samtools view -bS -F 256 - | \
			samtools sort -@ {threads} -o {output.shasta_to_hifiasm_alignment_bam} -
		
		# Index the BAM file
		samtools index {output.shasta_to_hifiasm_alignment_bam} {output.shasta_to_hifiasm_alignment_bai}

		# Generate analysePaf output
		{input.analyzePaf_bin} \
			--input {output.shasta_to_hifiasm_alignment_paf} \
			--output results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/hifiasm_to_shasta_alignment/{wildcards.sample_id}_{wildcards.region_id}_hifiasm_to_shasta_minimap_{wildcards.asm_preset} \
			--pixelsPerMb 5000 --minAlignmentQuality 0 > {log} 2>&1
		"""

rule generate_alignment_plot_for_shasta_to_hifiasm_alignment_for_ec_reads:
	output:
		alignment_plots_pdf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta_to_hifiasm_alignment/{sample_id}_{region_id}_shasta_to_hifiasm_{asm_preset}_alignment_plots.pdf"
	input:
		r_script="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts/generate_alignment_diagonal_plot.R",
		shasta_to_hifiasm_alignment_paf="results_hs/hs-{k}/{sample_id}/{region_id}/ec/shasta_to_hifiasm_alignment/{sample_id}_{region_id}_shasta_to_hifiasm_minimap_{asm_preset}.paf"
	params:
		asm_preset=config["MINIMAP"]["asmPreset"]
	benchmark: "benchmarks/{sample_id}/hs-{k}/{region_id}/generate_alignment_plot_for_shasta_to_hifiasm_alignment_for_ec_reads_{asm_preset}.benchmark.txt"
	log: "logs/{sample_id}/hs-{k}/{region_id}/generate_alignment_plot_for_shasta_to_hifiasm_alignment_for_ec_reads_{asm_preset}.log"
	resources:
		mem_mb=lambda wildcards, input, attempt: get_mem_mb(input, buffer_factor=1.2, min_mb=100),
		runtime=60*60,
		slurm_partition=choose_partition(60)
	shell:
		"""
		# Create output directory
		mkdir -p results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/shasta_to_hifiasm_alignment
		
		# Generate alignment diagonal plots
		Rscript {input.r_script} \
			{input.shasta_to_hifiasm_alignment_paf} \
			results_hs/hs-{wildcards.k}/{wildcards.sample_id}/{wildcards.region_id}/ec/shasta_to_hifiasm_alignment \
			{wildcards.sample_id}_{wildcards.region_id}_shasta_to_hifiasm_{wildcards.asm_preset} > {log} 2>&1
		"""

rule generate_run_summary_for_ec_reads:
    output:
        pga_log="results_hs/hs-{k}/{sample_id}/{region_id}/ec/pga_run.log"
    input:
        params_log="results_hs/hs-{k}/{sample_id}/{region_id}/ec/anchors/params_run.log",
        shasta_conf=config["SHASTA"]["conf"],
        script="/private/groups/migalab/shnegi/vg_anchors_project/test_lr_giraffe_assembly/workflow/scripts/generate_runlog.py"
    params:
        run_mode=config['RUN_MODE'],
        region_id=config['region_id'],
        asm_preset=config['MINIMAP']['asmPreset'],
        read_type=config.get('READ_TYPE'),
        run_gbz_query=config.get('RUN_GBZ_QUERY'),
        use_full_graph=config.get('USE_FULL_GRAPH'),
        run_debugging=config.get('RUN_DEBUGGING')
    shell:
        """
        python3 {input.script} --params-log {input.params_log} --shasta-conf {input.shasta_conf} --output-log {output.pga_log} --run-mode {params.run_mode} --region-id {params.region_id} --asm-preset {params.asm_preset} \
            --read-type {params.read_type} --run-gbz-query {params.run_gbz_query} --use-full-graph {params.use_full_graph} --run-debugging {params.run_debugging}
        """
